{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Authors: Jesse Simpson, Rafail Islam, Amber Gillenwaters\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nostop.lemmas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any NaN rows\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on subset of features\n",
    "df_features= df.iloc[:1000,0:3]\n",
    "df_label = df.iloc[:1000,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encode categorical\n",
    "df_features_transformed = pd.get_dummies(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_k = df_label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpectralClustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpectralClustering()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df_features_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2845707437008366, 0.856812169373565)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# A clustering result satisfies homogeneity if all of its clusters \n",
    "#contain only data points which are members of a single class.\n",
    "homogeneity = metrics.homogeneity_score(df_label.to_numpy(), model.labels_)\n",
    "# A clustering result satisfies completeness if all the data points \n",
    "# that are members of a given class are elements of the same cluster.\n",
    "completeness = metrics.completeness_score(df_label.to_numpy(), model.labels_)\n",
    "homogeneity, completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 'lobpcg', 99, 9, 1.9099760625681137, 'rbf', 9, 0.0, 'discretize', 3.0, 1]\n",
      "[12, 'lobpcg', 99, 6, 0.7725454599456996, 'rbf', 7, 0.0, 'kmeans', 3.0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Spectral Clustering Features\n",
    "'''\n",
    "0 n_clusters : int > 2\n",
    "1 eigen_solver: {None, 'arpack', lobpcg', 'amg'} # no amg since library failed\n",
    "2 random_state: int (constant)\n",
    "3 n_init: int > 2\n",
    "4 gamma : float (0-2)\n",
    "5 affinity: 'rbf'\n",
    "6 n_neighbors: int (2-15)\n",
    "7 eigen_tol: float - default 0.0\n",
    "8 assign_labels : {'kmeans', 'discretize'}\n",
    "9 degree : float default 3\n",
    "10 coef0: float default 1\n",
    "'''\n",
    "\n",
    "def create_spectral_cluster_parameters():\n",
    "    num_clusters = np.random.randint(low=2, high=16)\n",
    "    eigen_solver = np.random.choice([None, 'arpack', 'lobpcg'])\n",
    "    random_state = 99\n",
    "    n_init = np.random.randint(low=2, high=15)\n",
    "    gamma = np.random.uniform(low=0.0, high=2.0)\n",
    "    affinity = 'rbf'\n",
    "    n_neighbors = np.random.randint(low=2, high=15)\n",
    "    eigen_tol = 0.0\n",
    "    assign_labels = np.random.choice(['kmeans', 'discretize'])\n",
    "    degree = 3.0\n",
    "    coef0 = 1\n",
    "    \n",
    "    return [num_clusters, eigen_solver, random_state, n_init, gamma, affinity,\n",
    "                             n_neighbors, eigen_tol, assign_labels, degree, coef0]\n",
    "\n",
    "test1 = create_spectral_cluster_parameters()\n",
    "test2 = create_spectral_cluster_parameters()\n",
    "print(test1)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random parent selection\n",
    "def parent_selection(population):\n",
    "    p1 = np.random.randint(low=0, high=len(population)-1)\n",
    "    p2 = np.random.randint(low=0, high=len(population)-1)\n",
    "    return population[p1], population[p2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 'lobpcg', 99, 9, 1.9099760625681137, 'rbf', 9, 0.0, 'discretize', 3.0, 1]\n",
      "[12, 'lobpcg', 99, 6, 0.7725454599456996, 'rbf', 7, 0.0, 'kmeans', 3.0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['12', 'lobpcg', '99', '9', '0.7725454599456996', 'rbf', '7',\n",
       "        '0.0', 'kmeans', '3.0', '1']], dtype='<U21')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_over(p1, p2, length):\n",
    "    point = np.random.randint(low=1, high= length-2)\n",
    "    new_parameters = p1[:point]\n",
    "    new_parameters += p2[point:]\n",
    "    \n",
    "    return np.array(new_parameters).reshape(1, length)\n",
    "\n",
    "print(test1)\n",
    "print(test2)\n",
    "cross_over(test1, test2, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 'lobpcg', 99, 9, 1.9099760625681137, 'rbf', 9, 0.0, 'discretize', 3.0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12, 'lobpcg', 99, 9, 1.9099760625681137, 'rbf', 9, 0.0, 'discretize', 3.0, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "0 n_clusters : int > 2\n",
    "1 eigen_solver: {None, 'arpack', lobpcg', 'amg'}\n",
    "2 random_state: int (constant)\n",
    "3 n_init: int > 2\n",
    "4 gamma : float (0-2)\n",
    "5 affinity: 'rbf'\n",
    "6 n_neighbors: int (2-15)\n",
    "7 eigen_tol: float - default 0.0\n",
    "8 assign_labels : {'kmeans', 'discretize'}\n",
    "9 degree : float default 3\n",
    "10 coef0: float default 1\n",
    "'''\n",
    "\n",
    "def mutation(sample):\n",
    "    # Randomly mutate 1 parameter\n",
    "    index = np.random.randint(low=0, high=11)\n",
    "    \n",
    "    # handle constraints\n",
    "    if index == 0:\n",
    "        new_cluster_size = np.random.randint(2, 16)\n",
    "        sample[0] = new_cluster_size\n",
    "    elif index == 1:\n",
    "        new_solver = np.random.choice([None, 'arpack', 'lobpcg'])\n",
    "        sample[1] = new_solver\n",
    "    elif index == 2:\n",
    "        pass\n",
    "    elif index == 3:\n",
    "        new_init = np.random.randint(low=2, high=15)\n",
    "        sample[3] = new_init\n",
    "    elif index == 4:\n",
    "        new_gamma = np.random.uniform(low=0.0, high=2.0)\n",
    "        sample[4] = new_gamma\n",
    "    elif index == 5:\n",
    "        pass\n",
    "    elif index == 6:\n",
    "        new_neighbors = np.random.randint(low=2, high=15)\n",
    "        sample[6] = new_neighbors\n",
    "    elif index == 7:\n",
    "        pass\n",
    "    elif index == 8:\n",
    "        new_assign = np.random.choice(['kmeans', 'discretize'])\n",
    "        sample[8] = new_assign\n",
    "    elif index == 9:\n",
    "        pass\n",
    "    elif index == 10:\n",
    "        pass\n",
    "    \n",
    "    return sample\n",
    "        \n",
    "print(test1)\n",
    "mutation(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_fitness(model_labels, label_true):\n",
    "    homogeneity = metrics.homogeneity_score(label_true, model.labels_)\n",
    "    completeness = metrics.completeness_score(label_true, model.labels_)\n",
    "    return homogeneity + completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Epoch:  10\n",
      "Epoch:  11\n",
      "Epoch:  12\n",
      "Epoch:  13\n",
      "Epoch:  14\n",
      "Epoch:  15\n",
      "Epoch:  16\n",
      "Epoch:  17\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Hyper parameters\n",
    "population_size = 20\n",
    "number_gen = 50\n",
    "length = 11 # Changes depending on clustering algorithm parameter size\n",
    "num_rep = 10\n",
    "\n",
    "best_of_pop = []\n",
    "# Genetic algorithm\n",
    "# Parent Selection\n",
    "# Crossover\n",
    "# Mutation\n",
    "# Survivor\n",
    "for rep in range(num_rep):\n",
    "    population = [create_spectral_cluster_parameters() for _ in range(population_size)]\n",
    "    for gen in range(number_gen):\n",
    "        child_pop = []\n",
    "        for _ in range(population_size):\n",
    "            # Parent Selection\n",
    "            parent1, parent2 = parent_selection(population)\n",
    "\n",
    "            # Crossover\n",
    "            child = cross_over(parent1, parent2, length).tolist()\n",
    "            child = list(itertools.chain(*child))\n",
    "\n",
    "            # Mutation\n",
    "            child = mutation(child)\n",
    "\n",
    "            child_pop.append(child)\n",
    "\n",
    "        # Survivor Selection - Calculate Fitness, replace worst in population with best child\n",
    "        # Create Models for each parameter list, evaluate fitness\n",
    "        # Have to try/except all parameters since there is some linear algebra limitations\n",
    "        # that can be broken from random mutation/crossover\n",
    "        model_pop = []\n",
    "        child_model_pop = []\n",
    "        for i, sample in enumerate(population):\n",
    "            try:\n",
    "                model = SpectralClustering(n_clusters=sample[0], eigen_solver=sample[1], random_state=sample[2],\n",
    "                                    n_init=sample[3], gamma=sample[4], affinity=sample[5], \n",
    "                                     eigen_tol=sample[7], assign_labels=sample[8], degree=sample[9], coef0=sample[10])\n",
    "\n",
    "                fitness =  get_fitness(model.fit(df_features_transformed).labels_, df_label.to_numpy())\n",
    "            except:\n",
    "                flag = True\n",
    "                while flag:\n",
    "                    new_sample = create_spectral_cluster_parameters()\n",
    "                    try:\n",
    "                        model = SpectralClustering(n_clusters=new_sample[0], eigen_solver=new_sample[1], random_state=new_sample[2],\n",
    "                                            n_init=new_sample[3], gamma=new_sample[4], affinity=new_sample[5], \n",
    "                                             eigen_tol=new_sample[7], assign_labels=new_sample[8], \n",
    "                                                   degree=new_sample[9], coef0=new_sample[10])\n",
    "\n",
    "                        fitness =  get_fitness(model.fit(df_features_transformed).labels_, df_label.to_numpy())\n",
    "                        flag = False\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "\n",
    "            # Append sample and fitness \n",
    "            model_pop.append([sample, fitness])\n",
    "\n",
    "        for i, sample in enumerate(child_pop):\n",
    "            try:\n",
    "                model = SpectralClustering(n_clusters=sample[0], eigen_solver=sample[1], random_state=sample[2],\n",
    "                                    n_init=sample[3], gamma=sample[4], affinity=sample[5], \n",
    "                                     eigen_tol=sample[7], assign_labels=sample[8], degree=sample[9], coef0=sample[10])\n",
    "\n",
    "                fitness =  get_fitness(model.fit(df_features_transformed).labels_, df_label.to_numpy())\n",
    "            except:\n",
    "                flag = True\n",
    "                while flag:\n",
    "                    new_sample = create_spectral_cluster_parameters()\n",
    "                    try:\n",
    "                        model = SpectralClustering(n_clusters=new_sample[0], eigen_solver=new_sample[1], random_state=new_sample[2],\n",
    "                                            n_init=new_sample[3], gamma=new_sample[4], affinity=new_sample[5], \n",
    "                                             eigen_tol=new_sample[7], assign_labels=new_sample[8], \n",
    "                                                   degree=new_sample[9], coef0=new_sample[10])\n",
    "\n",
    "                        fitness =  get_fitness(model.fit(df_features_transformed).labels_, df_label.to_numpy())\n",
    "                        flag = False\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "\n",
    "            # Append sample and fitness \n",
    "            child_model_pop.append([sample, fitness])\n",
    "\n",
    "        sorted_pop = sorted(model_pop, key=lambda fit: fit[1])\n",
    "        sorted_child_pop = sorted(child_model_pop, key=lambda fit: fit[1])\n",
    "        sorted_pop[-1] = sorted_child_pop[0]\n",
    "        population = [sample[0] for sample in sorted_pop]\n",
    "        print(\"Epoch: \", gen)\n",
    "    best_of_pop.append(population[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pca = PCA(n_components= 2)\n",
    "data, label = df_features_transformed, df_label.to_numpy()\n",
    "\n",
    "foldername = None\n",
    "filename = None\n",
    "\n",
    "X1, X2 = np.transpose(pca.fit_transform(data))\n",
    "\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "\n",
    "# Markers\n",
    "# matplotlib markers: https://matplotlib.org/3.1.1/api/markers_api.html\n",
    "# matplotlib colors: https://matplotlib.org/3.1.1/users/dflt_style_changes.html\n",
    "markers = ['s', 'h', '^', 'D', 'o']\n",
    "unique = np.unique(label)\n",
    "for j, i in enumerate(unique):\n",
    "    X_r1 = [X1[j] for j in range(len(X1)) if label[j] == i]\n",
    "    X_r2 = [X2[j] for j in range(len(X2)) if label[j] == i]\n",
    "    l = [label[j] for j in range(len(label)) if label[j] == i]\n",
    "    plt.scatter(X_r1, X_r2, label = l)\n",
    "    \n",
    "\n",
    "#plt.savefig(foldername+filename, dpi=fig.get_dpi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISO\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "array = df_features_transformed.copy()\n",
    "iso = Isomap(n_components=2)\n",
    "iso.fit(array)\n",
    "manifold_2Da = iso.transform(array)\n",
    "manifold_2D = pd.DataFrame(manifold_2Da, columns=['Component 1', 'Component 2'])\n",
    "\n",
    "fig = plt.figure()\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "X1 = manifold_2D['Component 1']\n",
    "X2 = manifold_2D['Component 2']\n",
    "unique = np.unique(label)\n",
    "\n",
    "for j, i in enumerate(unique):\n",
    "    X_r1 = [X1[j] for j in range(len(X1)) if label[j] == i]\n",
    "    X_r2 = [X2[j] for j in range(len(X2)) if label[j] == i]\n",
    "    l = [label[j] for j in range(len(label)) if label[j] == i]\n",
    "    plt.scatter(X_r1, X_r2, label = l)\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig(foldername+filename, dpi=fig.get_dpi())\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(df_features_transformed)\n",
    "\n",
    "X1 = tsne_results[:,0]\n",
    "X2 = tsne_results[:,1]\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "\n",
    "unique = np.unique(label)\n",
    "for j, i in enumerate(unique):\n",
    "    X_r1 = [X1[j] for j in range(len(X1)) if label[j] == i]\n",
    "    X_r2 = [X2[j] for j in range(len(X2)) if label[j] == i]\n",
    "    l = [label[j] for j in range(len(label)) if label[j] == i]\n",
    "    plt.scatter(X_r1, X_r2, label = l)\n",
    "    \n",
    "plt.show()\n",
    "#plt.savefig(foldername+filename, dpi=fig.get_dpi())\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
